{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# input_text = \"translate English to German: How old are you?\"\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = model.generate(input_ids)\n",
    "# print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nimra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"shorthillsai/flan-t5-large-absa\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shorthillsai/flan-t5-large-absa\", truncation=True)\n",
    "\n",
    "prompt = \"\"\"Find the aspect based sentiment for the given review. 'Not present' if the aspect is absent.\\n\\nReview:I love the screen of this laptop and the battery life is amazing.\\n\\nAspect:Battery Life\\n\\nSentiment: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\").input_ids\n",
    "instruct_model_outputs = model.generate(input_ids=input_ids)\n",
    "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment_t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAMS/ACSA_test</td>\n",
       "      <td>We went again and sat at the bar this time, I ...</td>\n",
       "      <td>place</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAMS/ACSA_test</td>\n",
       "      <td>We went again and sat at the bar this time, I ...</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAMS/ACSA_test</td>\n",
       "      <td>The food was good, but it's not worth the wait...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset_name                                           sentence aspect  \\\n",
       "0  MAMS/ACSA_test  We went again and sat at the bar this time, I ...  place   \n",
       "1  MAMS/ACSA_test  We went again and sat at the bar this time, I ...   food   \n",
       "2  MAMS/ACSA_test  The food was good, but it's not worth the wait...   food   \n",
       "\n",
       "   polarity sentiment_t5  \n",
       "0   neutral     Negative  \n",
       "1  negative     Negative  \n",
       "2  positive      Neutral  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = \"flan_t5/results/\"\n",
    "data_path=\"MAMS/\"\n",
    "filename=\"ACSA_test\"\n",
    "if(os.path.isfile(path+data_path+filename+\"_t5.csv\")):\n",
    "    res = pd.read_csv(path+data_path+filename+\"_t5.csv\")\n",
    "else:\n",
    "    res = pd.DataFrame(columns=['dataset_name', 'sentence', 'aspect', 'polarity', 'sentiment_t5'])\n",
    "print(len(res))\n",
    "res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect_category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We went again and sat at the bar this time, I ...</td>\n",
       "      <td>place</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We went again and sat at the bar this time, I ...</td>\n",
       "      <td>food</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence aspect_category  polarity\n",
       "0  We went again and sat at the bar this time, I ...           place   neutral\n",
       "1  We went again and sat at the bar this time, I ...            food  negative"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('processed_'+data_path+filename+'_single.csv')\n",
    "# df = pd.read_csv('processed_'+data_path+filename+'_single.csv')\n",
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate each Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 901\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['aspect_category'], inplace=True)\n",
    "print(len(df), len(res))\n",
    "# for sentence, aspec, senti in zip(df['sentence'][len(res):1],df['aspect_term'][len(res):1], df['polarity'][len(res):1]):\n",
    "for sentence, aspec, senti in zip(df['sentence'][len(res):],df['aspect_category'][len(res):], df['polarity'][len(res):]):\n",
    "    temp = pd.DataFrame(columns=['dataset_name', 'sentence', 'aspect', 'polarity', 'sentiment_t5'])   \n",
    "    prompt = f\"\"\"Review: {sentence}\n",
    "    Aspect List: {aspec.replace('#', ' ').lower()}\n",
    "    Predict the sentiment for mentioned aspect in the review. Assign one of the following sentiment to the aspect: Positive , Negative , Neutral.\n",
    "    Please provide the sentiment only. No any explanation or extra text\"\"\"\n",
    "    # print(prompt)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\").input_ids\n",
    "    instruct_model_outputs = model.generate(input_ids=input_ids)\n",
    "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    data_to_append = {\n",
    "    'dataset_name': data_path+filename,\n",
    "    'sentence': sentence,\n",
    "    'aspect': aspec,\n",
    "    'polarity': senti,\n",
    "    'sentiment_t5': instruct_model_text_output \n",
    "    }\n",
    "\n",
    "    print(data_to_append)\n",
    "    temp = temp.append(data_to_append, ignore_index=True)\n",
    "    file_path = path+data_path+filename+\"_t5.csv\"\n",
    "    if os.path.exists(file_path):   \n",
    "        temp.to_csv(file_path, index=False, mode='a', header=False)\n",
    "    else:\n",
    "        temp.to_csv(file_path, index=False, mode='a')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Old Prompt\n",
    "# for sentence, aspec, senti in zip(df['sentence'][len(res):1],df['aspect_category'][len(res):1], df['polarity'][len(res):1]):\n",
    "# # for sentence, aspec, senti in zip(df['sentence'][len(res):],df['aspect_category'][len(res):], df['polarity'][len(res):]):\n",
    "#     temp = pd.DataFrame(columns=['dataset_name', 'sentence', 'aspect', 'polarity', 'sentiment_t5'])\n",
    "#     prompt = f\"\"\"Find the aspect based sentiment for the given review. 'Not present' if the aspect is absent.\n",
    "#     \\n\\nReview: {sentence.lower()}.\n",
    "#     \\n\\nAspect: {aspec.replace('#', ' ').lower()} \\n\\nSentiment: \"\"\"\n",
    "#     # print(prompt)\n",
    "#     input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\").input_ids\n",
    "#     instruct_model_outputs = model.generate(input_ids=input_ids)\n",
    "#     instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#     data_to_append = {\n",
    "#     'dataset_name': data_path+filename,\n",
    "#     'sentence': sentence,\n",
    "#     'aspect': aspec,\n",
    "#     'polarity': senti,\n",
    "#     'sentiment_t5': instruct_model_text_output \n",
    "#     }\n",
    "\n",
    "#     print(data_to_append)\n",
    "#     temp = temp.append(data_to_append, ignore_index=True)\n",
    "#     temp.to_csv(path+data_path+filename+\"_category_t5.csv\", index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ABSA work\\\\codes'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
